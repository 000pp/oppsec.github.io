
[{"content":"","date":"20 February 2025","externalUrl":null,"permalink":"/","section":"1337.coffee","summary":"","title":"1337.coffee","type":"page"},{"content":"","date":"20 February 2025","externalUrl":null,"permalink":"/tags/flutter/","section":"Tags","summary":"","title":"Flutter","type":"tags"},{"content":" Summary # Introduction Less talk, show me the code! SSL Pinning for you, not for me! Intercept, intercept and intercept References Introduction # Continuing with my mobile pentest studies—and, of course, doing mobile pentests at work—it\u0026rsquo;s pretty common to run into different mobile apps built with various programming languages. For example, you’ll find apps developed in Java, Kotlin, Flutter, Xamarin, Swift… and a bunch of others.\nSo far, I’ve only worked with Java and Flutter apps, but I’m looking forward to exploring others. What am I getting at here? Basically, what\u0026rsquo;s the difference between decompiling a Java app and a Flutter app? Simple: you can\u0026rsquo;t just open Flutter apps in JADX and call it a day :(\nYou\u0026rsquo;ll probably find only a few class files that won’t be nearly as helpful as you\u0026rsquo;d hope. For example, here’s the app I’m currently wrestling with:\nAs you can see, we only have a MainActivity file, a class file with a random name, and the BuildConfig file (don’t forget to check the BuildConfig file—you might find something useful there). When I see this, two scenarios come to mind:\nThe rest of the app is obfuscated. The app is built with Flutter. I went with the second option. Why? Because it\u0026rsquo;s pretty easy to identify a Flutter app just by looking at the extracted content from the APK file (I used apktool for this) and checking the lib directory.\nFor now, we\u0026rsquo;re most interested in these two files: libflutter.so and libapp.so. For those who don’t know, Flutter is a software development kit created by Google, commonly used to develop applications for Android, iOS, Linux, macOS, and other platforms. However, it’s primarily popular for mobile apps.\nThe libflutter.so file contains the Flutter engine, mainly developed in C++. One of its key components is Skia (a 2D graphics library), which renders the UI and displays it in the FlutterView, also known as the Raster Thread. There’s also the Platform Thread, which interacts with the native APIs of Android and iOS. Finally, we have the UI Thread, responsible for executing Dart code and managing widgets.\nOn the other hand, libapp.so is unique to each Flutter application. It contains the compiled Dart project—essentially, the mobile app’s source code. This code is compiled into native machine code using AOT (Ahead-of-Time) compilation, meaning the code is translated into machine instructions before the app actually runs, typically during the production build.\nAs stated in the Dart documentation, AOT-compiled code guarantees better performance during application execution, such as a fast startup and consistent runtime performance, unlike JIT-compiled code, which is slower at startup but can reach better performance after some time when necessary runtime optimizations occur. Naturally, during a fast development cycle, the Dart VM offers developers JIT compilation features like hot reload, live metrics collection, and debugging support, which help a lot in thoroughly testing the application.\nhttps://medium.com/flutter/flutter-dont-fear-the-garbage-collector-d69b3ff1ca30\nWhen apps are finally ready to be deployed to web applications or app stores, you can compile your application with the Dart AOT compiler to native ARM or x64 machine code, which, as discussed earlier, will offer better startup performance for your entire application. The AOT-compiled code will run inside the Dart runtime environment with a memory management system that employs fast garbage collection and a generational garbage collector.\nIn the final process, the libflutter.so file launches the Flutter engine and sets up the environment, while the libapp.so file is loaded by the Flutter engine. This allows the Dart code to run within the Flutter engine, powered by libflutter.so.\nFlutter Architectural Overview - Flutter\nLess talk, show me the code! # To provide more context, if we open a generic Java application in decompilation tools like JADX and the app does not use any obfuscation solution, the reverse-engineering process becomes extremely easy since the code is human-readable. For example, I downloaded a specific application from the Play Store and decompiled the APK file using JADX. By following the package name in the Source Code tab and accessing the Java files, you can see that everything is much easier to understand.\nGetting Flutter\u0026rsquo;s apps source code isn’t exactly trivial. You could open the libapp.so file in Ghidra, IDA, BinaryNinja, or whatever tool you prefer, and try your best to figure out what\u0026rsquo;s going on. But honestly, I prefer a different approach. It’s not a secret method, just a more efficient one (at least in my opinion).\nThankfully, Worawit, along with six other contributors, created the Blutter project. Blutter is a Flutter reverse-engineering tool that supports arm64 and allows lazy people like us to extract more readable code and structure from a Flutter app. It’s super simple to use, though you\u0026rsquo;ll need some libraries and dependencies set up. In my case (MacOS), I had to install cmake, ninja, pkg-config, icu4c, llvm, and a few others. BUT! For actually running Blutter, all you need is a Python script.\nAs the Blutter README explains, you just need to run the Python script, specify the path to the arm64-v8a directory, and set an output directory:\npython3 blutter.py path/to/app/lib/arm64-v8a out_dir After that, Blutter compiles the necessary libraries and extracts some resources to execute the reverse-engineering process. Hopefully, after a few minutes, your output will look similar to mine. If any errors occur during this process or your PC crashes, make sure to read the stack trace carefully and check the Blutter GitHub repository\u0026rsquo;s Issues tab for similar problems. For added context, I\u0026rsquo;m running this on a MacBook, I haven\u0026rsquo;t tried Blutter on any other OS yet.\nIf we navigate to our previously created output directory (in this case, I named it decompiled_code) and access the files, we now see a bunch of directories. It contains all the libraries used by the app and the app itself. If you look further, you can find your targeted directory based on the application package name.\nThe blurred directories are our target. From here, you can either dig through the countless files Blutter extracted or, like me, open the directory in VSCode for a more user-friendly overview. You\u0026rsquo;re probably going to see a structure similar to the image below. Now it\u0026rsquo;s 10 times easier to understand the application architecture and focus on the most important parts of the code.\nNow we have a much better environment for reverse engineering the mobile application and searching for vulnerabilities. I highly recommend using gitleaks or any secret-finding tool (TruffleHog, Semgrep) to identify low-hanging fruits. I did this and found some interesting results, but that\u0026rsquo;s not the focus of this article, so we will skip that part.\nSSL Pinning for you, not for me! # SSL Pinning (or Certificate Pinning) is a technique that helps developers secure their mobile apps from Man-in-the-Middle (MITM) attacks. It ensures that the app only trusts specific certificates instead of the entire certificate chain. Instead of trusting any valid certificate chain, the application stores a copy of the server\u0026rsquo;s certificate or public key and verifies if the connection uses that exact certificate.\nIn the context of SSL Pinning, there are different pinning approaches. For example, we have Public Key Pinning, which is a mechanism for sites to specify which certificate authorities have issued valid certificates for that specific site, and to reject TLS connections to those sites if the used certificate is not issued by a known-good CA. The idea is also to prevent man-in-the-middle attacks by hard-coding the public key of the server\u0026rsquo;s SSL certificate instead of the entire certificate. In this way, the client will check if the server certificate contains the same public key that is hard-coded in the application code. The main advantage of Public Key Pinning is that even if the server certificate changes, the client will still trust the server if the public key remains the same, although it is harder to implement.\nAnother method is SPKI Pinning. The Subject Public Key Info (SPKI) is basically the key with a bit more salt, it can include the algorithm used for encoding or other parameters. SPKI is obtained from the Certificate Signing Request (CSR), which collects the necessary information from a pair of public and private keys. The use of SPKI Pinning is not very convenient because you will need to release a mandatory update of your app when the certificate gets renewed, which will probably make things harder to maintain. It is possible to \u0026ldquo;bypass\u0026rdquo; this problem if you keep the same Certificate Signing Request (CSR) on every renewal process, but that violates the key rotation principle, which is the process of replacing old encryption keys with new ones to reduce the risk of compromised keys.\nWhile analyzing the source code extracted by Blutter, I found something interesting that caught my attention. In the project files, there was a file called dio_http_service_imp.dart. Dio is a popular HTTP networking package for Dart/Flutter, supporting TLS connections. From the official Dio documentation, this is the basic implementation:\nvoid initAdapter() { const String fingerprint = \u0026#39;ee5ce1dfa7a53657c545c62b65802e4272878dabd65c0aadcf85783ebb0b4d5c\u0026#39;; dio.httpClientAdapter = IOHttpClientAdapter( createHttpClient: () { final HttpClient client = HttpClient(context: SecurityContext(withTrustedRoots: false)); client.badCertificateCallback = (cert, host, port) =\u0026gt; true; return client; }, validateCertificate: (cert, host, port) { if (cert == null) return false; return fingerprint == sha256.convert(cert.der).toString(); }, ); } As we can see above, we start by defining a variable called fingerprint that will contain the SHA256 hash of the public certificate key. After that, we create the HttpClient, ensuring that the SecurityContext is set with withTrustedRoots set to false so that we don\u0026rsquo;t trust any certificate just because its root cert is trusted. Furthermore, we check if the certificate fingerprint matches the SHA256 hash and ensure that at least one certificate is being supplied.\nIt works perfectly for servers that have a self-signed certificate, however, it will not work for external certificates issued by AWS, Let\u0026rsquo;s Encrypt, or other third parties. Therefore, we can verify the root of the HTTPS certificate that is provided by the server. The code below is an example of using a static PEM certificate and SecurityContext. It also supports PKCS#12 certificates, but PKCS#12 certificates require a password to be used, which exposes the password in the code; hence, the project does not recommend using them in common cases.\nvoid initAdapter() { String PEM = \u0026#39;XXXXX\u0026#39;; // Root certificate content dio.httpClientAdapter = IOHttpClientAdapter( onHttpClientCreate: (_) { final SecurityContext sc = SecurityContext(); sc.setTrustedCertificates(File(pathToTheCertificate)); final HttpClient client = HttpClient(context: sc); return client; }, ); } The most interesting part is this line sc.setTrustedCertificates(File(pathToTheCertificate)); This indicates that the app expects a static certificate file. After reading this article by Mohamed Malkia, I immediately searched the source code for .pem and .key extensions. And guess what? I found actual references to these files:\nGoing back to VSCode and using the search function, I typed .pem in the \u0026ldquo;Search\u0026rdquo; field and immediately got two references in the code, again in the dio_http_service_imp.dart file. Acessing these files we can get more details about the usage of the Dio package.\nThe app reads the certificate bytes and implements them using Dart\u0026rsquo;s SecurityContext methods useCertificateChainBytes and usePrivateKeyBytes. According to the documentation:\nuseCertificateChainBytes: Sets the chain of X.509 certificates served by the SecureServerSocket during secure connections, including the server certificate. usePrivateKeyBytes: Sets the private key for the corresponding certificate. Interestingly, the application doesn\u0026rsquo;t use standard ports like 443, 80, or 8080. Instead, the API is hosted on port 444. This is crucial for properly configuring our proxy because if we try intercepting ports 443, 80, or 8080, we would probably only capture requests from third-party sources rather than those from the targeted application. Therefore, make sure to identify where the application is actually consuming data so that no important requests are missed.\nIt is important to note that every Certificate Pinning mechanism can be bypassed if the attacker has the necessary time and patience. The main idea of these mechanisms is to offer more security to users, reducing risk and making attackers\u0026rsquo; lives harder, but it will always be a cat-and-mouse game until vendors like Google and Apple develop technology to mitigate this problem (and I’m not even sure if that’s possible).\nIntercept, intercept and intercept # After all this analysis, we\u0026rsquo;re ready to intercept the traffic. Here\u0026rsquo;s what we need to do:\nCreate IPTables rules to redirect the traffic. Configure the proxy on our Android device (I\u0026rsquo;m using an emulated Pixel 9 Pro). Set up Burp Suite. Use the NVISO disable-flutter-tls script. Starting with IPTables, IPTables is a utility program from Linux that helps users configure network rules. In our case, it\u0026rsquo;s a really simple process—we just need to redirect the incoming traffic from port 444 to port 8080, where our Burp Suite proxy is running. The command I used for this is:\nemu64a:/ iptables -t nat -A OUTPUT -p tcp --dport 444 -j DNAT --to-destination \u0026lt;local-ip\u0026gt;:8080 emu64a:/ iptables -t nat -A POSTROUTING -p tcp -d \u0026lt;local-ip\u0026gt; --dport 8080 -j MASQUERADE After that, we need to go to our Wi-Fi settings on our Android device and change the proxy setting from “None” to “Manual,” specifying the host and port we want. In this case, the host will be your local IP and the port will be the same as the Burp Suite proxy. This will allow our emulated device to communicate with our Burp Suite proxy client.\nNow, for Burp Suite, we need to take the PEM and KEY files that are statically stored in the assets directory from the decompiled mobile app and generate a PKCS#12 file to later import into Burp Suite TLS settings. Why PKCS#12? Because Burp Suite TLS currently only supports PEM certificates.\nopenssl pkcs12 -export -out file.p12 -inkey key_file.key -in pem_file.pem -certifile pem_file.pem Here, the flags -export and -out specify that we want to write the certificate\u0026rsquo;s content to an output file. The -inkey flag specifies the private key from the certificate, combined with the -in and -certifile flags to indicate to OpenSSL which files are our certificates—we can repeat the PEM certificate file here.\nNow, go to your Burp Suite settings, navigate to the Network tab, and click on the “TLS” section. Scroll down to “Client TLS Certificates” and click the “Add” button to add a new certificate.\nIn the “Destination host” input, enter the host address from the API or website whose traffic you want to intercept (you don\u0026rsquo;t need to specify the port), and be sure to click the “File (PKCS#12)” radio button because you need to import your PKCS#12 file. After that, click the “Next” button.\nNext, click the “Select file” button and locate the .p12 file you generated using the OpenSSL command. During the process of generating the file with OpenSSL, you will be prompted to set a password; you must enter the same password in the “Password” field below the “Certificate file” field.\nIf everything goes well, your file will be loaded and you can even see some information about the imported certificate.\nNow for the final steps with Burp Suite, go to the Proxy settings and make sure the “Bind to port” is the same from the IPTables and change the “Bind to address” from “Specific addres” to “All interfaces” making sure we actually can intercept the traffic. After that, go the “Request handling” tab and check the “Support invisible proxying” checkbox.\nTo finish, download the NVISOsecurity Frida script to disable Flutter’s TLS verification, you can find it here. This script uses pattern matching to find ssl_verify_peer_cert in the handshake.cc file. The handshake.cc file is part of the BoringSSL project, a fork of OpenSSL used by Chrome/Chromium and Android. To execute the script, ensure that the Frida server is running on your Android device (it can be done via ADB) and run the following command:\nfrida -U -f your.package.name -l disable-flutter-tls.js --no-pause Don\u0026rsquo;t forget that you need to have the Burp Suite certificate installed on your device. There are various methods to do this, so I won\u0026rsquo;t cover that process here; however, you can find plenty of resources online that explain how to do it.\nFrida will run the app for us, so we go to Burp Suite and “HTTP History” tab we can see that now we can successfully intercept the app HTTP/HTTPS traffic.\nReferences # https://docs.flutter.dev/ https://dart.dev/overview https://onuoha.medium.com/how-does-jit-and-aot-work-in-dart-cab2f31d9cb5 https://github.com/worawit/blutter https://wiki.mozilla.org/SecurityEngineering/Public_Key_Pinning https://oleksandr-stepanov.medium.com/ssl-pinning-how-to-make-it-right-ecc5c9844215 https://owasp.org/www-community/controls/Certificate_and_Public_Key_Pinning https://medium.com/@melkia.med.taki/how-to-use-tls-ssl-in-flutter-with-dio-15eda4f80baf https://api.flutter.dev/flutter/dart-io/SecurityContext/usePrivateKeyBytes.html https://api.flutter.dev/flutter/dart-io/SecurityContext/useCertificateChainBytes.html https://github.com/NVISOsecurity/disable-flutter-tls-verification ","date":"20 February 2025","externalUrl":null,"permalink":"/posts/intercept-dio-brando-dart-package-https-requests/","section":"Posts","summary":"","title":"Intercepting Dio (Brando) Dart package HTTPS requests","type":"posts"},{"content":"","date":"20 February 2025","externalUrl":null,"permalink":"/tags/mobile/","section":"Tags","summary":"","title":"Mobile","type":"tags"},{"content":"","date":"20 February 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"20 February 2025","externalUrl":null,"permalink":"/tags/research/","section":"Tags","summary":"","title":"Research","type":"tags"},{"content":"","date":"20 February 2025","externalUrl":null,"permalink":"/tags/reverse-engineering/","section":"Tags","summary":"","title":"Reverse Engineering","type":"tags"},{"content":"","date":"20 February 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"20 January 2025","externalUrl":null,"permalink":"/tags/banking/","section":"Tags","summary":"","title":"Banking","type":"tags"},{"content":" Summary # Introduction I’m not fake, please let me in! Fighting invisible demons The final fight Conclusion References Introduction # A long time ago, I was looking for vulnerabilities in a Brazilian bank through a Bug Bounty platform. During that phase, I managed to report quite a few issues to them and earned a good amount of money. However, that platform was shut down, and I ended up stopping my tests on their systems.\nRecently, while browsing HackerOne, I noticed that the same bank is now there, but as a VDP this time. I decided not to test their web applications this time but instead focus on their mobile apps. Looking at the available options, I chose one of the apps that didn’t have many reports and seemed interesting to test.\nI already have a ready environment. In this case, I’m emulating a Pixel 7 Pro using Android Studio, and it’s rooted with the help of rootAVD and Magisk, which I believe is the easiest way to have an emulated Android device with the necessary permissions.\nrootAVD is a project developed by “newbit,” aimed at enabling us to root our Android Studio Virtual Device (AVD) using Magisk. It achieves this through a shell or batch script, which makes our lives much easier.\nMagisk is software developed by “topjohnwu” and various other contributors with the goal of allowing customization of Android devices starting from version 6.0. Magisk includes several modules, such as MagiskSU, probably the most famous, which provides root privileges to applications, Magisk Modules, which allows the use of custom modules within Magisk itself, and others.\nI also use the plugin MagiskTrustUserCerts by NVISOSecurity, which allowed me to install the Burp Suite certificate as an authority, avoiding issues when using Burp Suite to intercept application requests. The only concern would be dealing with SSL Pinning. We’re not using it at the moment, but it’s worth documenting.\nI recommend installing Android 13.0 with Google APIs so you can access the Play Store and download the apps directly from there. This ensures you have the most up-to-date version, likely free of malware, and functioning as expected. I even tried looking for the same app on sites like APKPure or APKCombo, but I wasn’t successful. Apparently, it hasn’t been listed or uploaded there yet.\nNone of these apps are our target. So, with one of my Google accounts connected to my emulated Android, I can download the app directly from the Play Store and proceed with the rest.\nAfter installing the application, I go to my terminal and extract the original APK using adb, in a very simple and practical way, so I can perform some static analyses such as information gathering and reverse engineering using Jadx. I like to use Frida to get the correct package name and use it to identify the correct APK path.\nAndroid Debug Bridge, or (adb), is a tool that allows debugging Android devices. Through it, I can interact with the AVD we created in Android Studio.\nJadx, on the other hand, is another tool that enables the decompilation of Android Dex files and APK files, which is very important since our target is precisely an Android application.\nFinally, the mighty Frida is a toolkit designed for developers, reverse engineers, and security researchers, aimed at enabling dynamic instrumentation of applications.\nBelow, I used the command frida-ps -Uai to list the applications installed on my AVD. The goal was to capture the full package name of the application.\nTo capture the full path of the application, I use the command adb shell pm path \u0026lt;package name\u0026gt;, then I use adb pull \u0026lt;path\u0026gt; to extract the APK to my local machine.\nThe first thing I like to do is use a set of tools to assist in the process of finding vulnerabilities in the target application. The ones I use the most are:\napkleaks: This tool returns various information about the APK, including possible hardcoded secrets, links, strings, and other elements. Apepe: A project of mine that lists various interesting details, such as all activities (including the app\u0026rsquo;s main activity), requested permissions, utilized libraries, and a list of services it uses or consumes. It also attempts to guess the app\u0026rsquo;s programming language based on the extracted content, though it\u0026rsquo;s not very precise. I was happy to use my project on this target app because it helped me identify a bug in the tool, which I was fortunately able to fix easily. The issue was with retrieving the app_name from the Androguard library.\nWith all this data collected, I proceed to use Jadx to read the application\u0026rsquo;s source code and begin identifying vulnerabilities. I examine key files, such as the AndroidManifest.xml, to look for intents, content providers, and so on. However, skipping over this step for now, I like to search for onResume() functions to examine the main initializers of the application. This revealed something very important:\nAs we can see, there are functions in the app that check if the device is rooted, if it is running in a development or staging environment, and if it is an emulator.\nI’m not fake, please let me in! # Let’s start with the isDeviceRooted() function, which is declared in a class called RootUtil. Within the same class, there are three functions that check whether the device is rooted in different ways. The first one is checkRootMethod1.\nThe first check captures the value of the TAGS property from android.os.Build and verifies if its value is test-keys. Another relevant point is that it’s a boolean function, so the final result will simply be true or false.\nThe function checkRootMethod2 creates an array with the standard paths of several SUID binaries and checks if the file exists using the java.io.File API and the exists() function. It’s worth noting that this is also a boolean function.\nThe last function, checkRootMethod3, executes the which command located at /system/xbin/which to check for any result pointing to the su binary by reading its output.\nSince all these checks are in the RootUtil class, we can create a JavaScript script and use Frida to intercept these calls and return the value false for each of these functions. This way, the app will always get a response like, “No, the device is not rooted.”\nFirst, we define the class and then interact with each function, passing their names directly through the variable rootUtils that we previously defined. In the end, the key part for each item is simply the return false. It’s also a good idea to alter the TAGS property as a precaution, which can be done using the defineProperty function.\nNow we just need to launch the app on our emulator using Frida, specifying its path with the -f argument and the JavaScript script we created earlier with the -l argument (don’t forget to start your Frida server).\nStrangely, we didn’t see any calls to the checkRootMethod functions, and the app already detected that we’re on an emulator. What’s my idea now? Bypass all protections at once and hope for the best xD. Currently, we have a possible bypass for the root check, so let’s apply the same process to the isEmulator and isDevOrHMLEnvironment functions.\nUsing Jadx, I searched for the definition of the word isEmulator() and found something interesting. As shown in the image below, the isEmulator() function is defined in both DeviceUtils.isEmulator() and DeviceUtils.Companion.isEmulator().\nAgain, these are boolean functions, so we’ll just return false for both and analyze how the application behaves now. The code looks like this:\nWith this, we’ll call our script again via Frida and observe how the application interacts now.\nNow, the app no longer immediately detects us as being on an emulator. However, we still have an issue: after a short time, a notification appears at the bottom of the app indicating that something malicious has been detected on our device, and the app will shut down.\nFighting invisible demons # What are they detecting now? We\u0026rsquo;ve already bypassed the checks for root, emulator, and development/staging environments, so what\u0026rsquo;s left?\nMy first idea was to monitor calls to other system properties, which is done through the System.getProperty function. So, let’s implement a function in our script to tell us what is being called and the values being sent.\nNote that I’m using the overload function because the System.getProperty method will likely be called multiple times with different parameters and so on.\nAs we can see, several properties are being called, and some of them have unexpected values. One very important one is http.agent, which clearly indicates it’s an emulator. Therefore, we’ll modify the return value for these properties.\nEven with all this configured, the app still closes. So, the issue doesn’t seem to be limited to property calls—there must be something else. Then, I got the idea to enumerate JSON objects, thinking that this information might be stored or sent to a server. I added the following code to my script:\nRunning the app again with Frida and our script, the result is as follows:\nThe app\u0026rsquo;s defense mechanism is detecting the presence of Magisk. The other reasons are likely also due to Magisk. In the censored section, the name of the solution protecting the app is displayed. So, now we need to bypass this solution!\nMagisk offers a module in its settings to change the package name. Let’s change it to something considered \u0026ldquo;legitimate\u0026rdquo; xD. I chose \u0026ldquo;SpotifyManager,\u0026rdquo; but any other name will work too.\nAfter this, Magisk will make the necessary changes, and we’ll need to confirm a few other things, though it’s unnecessary to detail them here. If we go back to our terminal and run the script again, we’ll see a surprise!\nMagisk is no longer being detected by the package name, leaving only the options \u0026ldquo;Superuser exists\u0026rdquo; and \u0026ldquo;Superuser system app installed.\u0026rdquo;\nTo resolve this, it’s quite simple: we just need to install the \u0026ldquo;Shamiko\u0026rdquo; and \u0026ldquo;LSPosed\u0026rdquo; modules in Magisk, and everything will work fine. These modules can successfully evade detection.\nShamiko is a module for Zygisk that hides the root process of Magisk, the Zygisk itself, and its modules, ensuring that protections cannot detect them through conventional means. For context, Zygisk is a Magisk module that allows us to run code in applications.\nTo install Shamiko, go to its creator’s GitHub page and download the zip file available in the GitHub Releases section.\nAfter downloading the zip file, move it to your sdcard with the command adb push \u0026lt;file\u0026gt; /sdcard and install it in Magisk. After installation, the \u0026ldquo;Restart\u0026rdquo; button will be available. Click it and wait for the AVD to reboot.\nOnce Shamiko is installed, let’s install LSPosed. LSPosed is a solution that allows us to modify the behavior of our Android device and system components in real-time. It’s available in another repository by the same creator. Download the zip, move it to your sdcard, and install it again. After installation, restart the emulator again.\nWith both installed, go to the Magisk settings and enable the \u0026ldquo;Enforce DenyList\u0026rdquo; option. I recommend restarting the emulator once more just to be sure. Then, navigate to the \u0026ldquo;Configure DenyList\u0026rdquo; option.\nNow, find the target app and check its checkbox. This will enable the DenyList for the app we want.\nWith that done, if we run our previous script again, we can see that the reasonData no longer contains Sudo/Superuser information, but it still detects the environment as an emulator.\nNow that we’ve hidden the root mode, let’s move on to the final step: figuring out how to convince the protection mechanism that we’re not an emulator.\nThe final fight # For quite some time, and with the help of some friends, we tried various ways to bypass the emulator detection—ranging from altering system properties to simulate a real device, to hooking some functions to understand what was actually happening behind the scenes. Unfortunately, we didn’t succeed until now.\nThe solution was to combine all the procedures we performed, the Frida script we developed, and a real device. In this case, I’d like to thank my friend thalysonz who conducted this test for me, as I don’t have a real Android device to test on. The result was that we could now run the application without being detected for the previously mentioned reasons, allowing us to proceed with any other tests we wanted to perform.\nIf, in the near future, we discover a way to bypass this emulator detection, I’ll update this article with the solution that made it possible.\nConclusion # In the end, it was an incredibly educational process. Since I don’t have much experience with mobile pentesting, dealing directly with a banking application that has several protections—though perhaps not as many as other banks—offered a real challenge throughout this process.\nI hope you were able to learn something from this article or that it served as inspiration for you to continue your studies. Thank you very much!\nReferences # https://github.com/dwisiswant0/apkleaks https://github.com/oppsec/Apepe https://gitlab.com/newbit/rootAVD https://github.com/topjohnwu/Magisk https://8ksec.io/advanced-frida-mobile/ https://labs.cognisys.group/posts/Writing-your-first-Frida-script-for-Android/ https://github.com/skylot/jadx https://github.com/LSPosed/LSPosed ","date":"20 January 2025","externalUrl":null,"permalink":"/posts/bypassing-protections-of-a-banking-app-just-to-learn/","section":"Posts","summary":"","title":"Bypassing protections of a banking app just to learn","type":"posts"},{"content":" Summary # Introduction Escalating from \u0026ldquo;cmdsh\u0026rdquo; Attacking the Web App Improving the Vulnerability’s Exploitability Automating the Process Conclusion References Introduction # Everything started when I watched a talk by Maycon Vitali at H2HC titled “Internet of Sh!t - Maycon Vitali - H2HC University 2018,” where he discussed his process of discovering vulnerabilities in a Ubiquiti router. After watching the 30-minute talk, I stopped the video, looked around, and remembered an old router I used to have and still had in my house.\nI immediately searched for the power cable, plugged it in next to my desk, and checked if everything worked fine. After about 5 minutes, I scanned my network and found the router\u0026rsquo;s IP address. I made some changes and set the IP to 192.168.15.1. With everything set up, I ran nmap to check the available ports and running services.\nWhen I saw the SSH port, I looked behind the router for any credentials and, fortunately, it had them. I tried logging in with the “admin” username, but it didn’t work, so I searched for some documentation and discovered the correct username was “support.”\nAs shown in the image above, we couldn’t execute commands or interact with the operating system beyond the initial shell. The initial goal was to figure out how to execute commands, as I had no prior experience with hardware hacking and didn’t want to attempt extracting the firmware without understanding how to do it.\nAfter a bit of research, I discovered that you could pass a direct command after the SSH command to escape the “dumb shell” we encountered when connecting.\nUsing the netstat command, I checked all running ports and services. The idea here is to find some binary or service we can exploit to discover a vulnerability, but we don\u0026rsquo;t investigate it too deeply and move on to other enumerations.\nThrough the uname -a command, I identified the version of the running Linux system. As you can see, it’s a fairly up-to-date kernel, and the environment is somewhat limited, so we also chose not to delve too deeply into its exploitation because, above all, our user is already part of the root group.\nLinux (none) 4.4.115 #1 SMP Fri Jul 5 16:58:21 CST 2024 armv7l GNU/Linux Using ps w, I also found a bunch of interesting information. There are several processes using some config files, including some XMLs that contain virtually all the router\u0026rsquo;s configurations, but we also didn\u0026rsquo;t find anything of significant relevance.\nAfter experimenting with the router, I discovered some issues:\nMy friends and I tried different methods to get a reverse shell, but without success. Some common binaries, like ls, didn’t work. The entire router was running on a read-only system, so we couldn’t create a web shell in the web app’s directory. Not having ls wasn’t a problem because we still had the find binary. For example:\nWhen I listed the files in the /tmp directory, I found a file called dump.txt that caught my attention. Reading this file, I discovered it stored network passwords in plaintext, along with other network configurations, which is indeed quite useful if you want to access the Wi-Fi network without changing it, which I think is the best option. The contents of the file were something like this:\nOk, I don\u0026rsquo;t think this is the biggest problem we have xD, but it\u0026rsquo;s still funny to see the level of security here. Let\u0026rsquo;s continue\u0026hellip;\nEscalating from cmdsh # Analyzing the processes, I discovered that the initial shell we got when accessing via SSH was called “cmdsh” and appeared to be a unique binary used to manage the SSH service. I copied the “cmdsh” binary to my local machine and opened it in Binary Ninja to understand what was happening in the background.\nWe can see that the binary looks for two variables called “LOGNAME” and “LOGFROM.” Digging further into the code, we identified the expected values for these variables\nThe most interesting part of this code, in my opinion, is the lines:\ncurrent_hidden and current_permission Why is this interesting? Because we can see the difference in permissions available when logged in with an “admin” or “telefonica” profile. So, before running the command /bin/cmdsh, we specify the values LOGNAME=telefonica, for example, and now the commands become available to us. =)\nAttacking the Web App # I wasn’t successful with cURL, wget, or SCP. So, I decided to create a tar file, convert it to base64, and save the output locally. After this, I converted it back into a normal file and successfully retrieved the content. I created the tar file from the directory /usr/shared/web. Opening it in VSCode revealed the following:\nIn the end, we have a \u0026ldquo;valid\u0026rdquo; code that we can open in VSCode to better understand the application\u0026rsquo;s structure, but not everything is as smooth as we imagined. This is an issue I didn\u0026rsquo;t consider at the time I was exporting it to VSCode.\nOf course, we couldn’t read the CGI files directly because they are compiled C files that generate a web interface (I think xD). I started exploring the available functions in the web app and found a menu called “Tools.” Accessing it, we saw options to run commands like Ping, Traceroute, and Nslookup.\nThis immediately caught my attention. I tried injecting direct commands into it, but there was a JavaScript validation that checked for valid IPs. However, we could bypass this by capturing a valid request in Burp Suite and modifying the IP parameter.\nAs we observed, there was some form of protection against command injection. By examining the code, we could understand how the function worked and look for ways to bypass or understand what was happening in the background.\nLooking at the final lines of the code, where the nslookup binary runs, we noticed that our input was directly concatenated into the execution. This confirmed that there was command injection. Another interesting detail was that the output was saved to the file /tmp/ping_result. To confirm if our commands were being executed, we needed to read this file.\nReturning to the web app, we kept trying to execute commands without immediate success. After a break, we discovered that the \u0026amp; character wasn’t blocked. For now, we could encode the \u0026amp; character with URL encoding and attempt to execute commands like this:\n127.0.0.1%26%26id We received a blank response because the output was rendered in another file. We just needed to send the request and then read the content of the ping_result file.\nFinally, we achieved command execution. The issue here was that it was a Blind Authenticated RCE because the output was saved in /tmp/ping_result, and we couldn’t read this file outside SSH. The web app didn’t render the command output directly.\nIf we look at the output of our command now, we’ll be surprised by something quite unfortunate, but something we managed to solve later, which was rather \u0026ldquo;funny\u0026rdquo; given the ideas we came up with during this process.\nBut this wasn’t a dead end for us! Here’s what we discovered:\nThe function that printed the command output removed some lines from the final result, so we couldn’t see the output without reading ping_result from the /tmp directory. There was a slight delay between command execution and when the output was saved, so we needed to wait about 5 seconds before checking the output. To work around this, we needed to concatenate three commands. Why? By using two nslookup commands, we ensured our command’s output wasn’t the last line removed by the application. =)\n127.0.0.1%26%26uname%20-a%26%26nslookup%20127.0.0.1 Automating the Process # Looking at the login process, we noticed the parameter loginPassword didn’t send the password in plaintext. Instead, it sent an MD5 hash of the password. After logging in, a COOKIE_SESSION_KEY was generated, which indicates that our session is valid and we are authenticated in the environment.\nLogging in again showed that the loginPassword value was different from the first login. Apparently, there is a function in the system that ensures the password hash doesn\u0026rsquo;t repeat, which I believe is meant to prevent brute force attacks and similar methods.\nInspecting the login.cgi HTML source code, we found the JavaScript function that generated the MD5 hash, the function in question is called \u0026ldquo;checkLogin,\u0026rdquo; and it seems to mix the SID value, the original password (in plain text), and finally convert everything to MD5.\nRefreshing the page showed that the sid value changed each time, this indicates that every time we access the login page, the SID will be changed, something like dynamic generation, so it\u0026rsquo;s not possible to simply convert our password to MD5 and send it directly to the login form.\nOur Python script needed to capture the var sid value, concatenate it with the password, and generate the MD5 hash. Using BeautifulSoup, we captured the var sid value after the = character with the following code:\nThis is already enough for us to generate a valid hash when submitting it to the login form after updating the code. We executed the script and checked the response:\nNow, with a valid COOKIE_SESSION_KEY, we could perform authenticated actions on the router. The final step was to replicate the process and integrate it into the script.The final result of our script will be an RCE with direct output, which made exploiting the vulnerability ten times better.\nConclusion # During this process, my friends and I realized that the most ridiculous ideas can work, like concatenating three commands and hoping for the best hahahaha xD. But honestly, it’s interesting how watching an H2HC talk sparked this desire in me to explore something I had such easy access to, and in the end, everything worked out. Obviously, all of this was possible thanks to the help of the other members of Inferi, who were exceptional in helping me brainstorm some ideas.\nIt’s funny that I have no experience with reverse engineering, but a little bit of guesswork and determination seems to solve everything. Of course, if I had some experience, it would have helped a lot, but that’s something for the future.\nThank you for reading this far! I hope you’ve learned something or at least enjoyed the content. Neither the script nor the vulnerability will be made available since this was just field research. But who knows? Maybe this will turn into a CVE in the future, and we’ll change our minds about publishing it.\nReferences # https://www.youtube.com/watch?v=4_UI9zBLJp0 ","date":"10 January 2025","externalUrl":null,"permalink":"/posts/discovering-0-day-authenticated-rce-on-my-router/","section":"Posts","summary":"","title":"Discovering a 0-day Authenticated RCE on my router","type":"posts"},{"content":"","date":"10 January 2025","externalUrl":null,"permalink":"/tags/exploit/","section":"Tags","summary":"","title":"Exploit","type":"tags"},{"content":"","date":"10 January 2025","externalUrl":null,"permalink":"/tags/web-exploitation/","section":"Tags","summary":"","title":"Web Exploitation","type":"tags"},{"content":" What is Azure and Blob? # Azure, or Microsoft Azure, is a cloud computing platform maintained by Microsoft that offers a bunch of services used by many companies and individuals. Probably, the most famous solutions provided by Microsoft Azure are virtual machines, Azure Kubernetes Services (AKS), solutions for DevOps and DevSecOps, and of course, the giant integration with all other Microsoft services, for example, Active Directory, GitHub, Azure DevOps, Visual Studio, and GitHub Copilot.\nNow, what is Azure Blob Storage? Azure Blob Storage is a massively scalable and secure object storage solution for cloud-native workloads, archives, data lakes, HPC, and machine learning (I took this from the Microsoft Azure Blob Storage website). Basically, a lot of companies store their files like videos, documents, executables, logs, backup data, and others in this service and share these resources through their services like web apps, systems, etc.\nA Blob Storage is constructed of three types of resources, which are:\nStorage Account: A Storage Account is the unique namespace for your Azure data. So, if you store your data on Azure Storage, your data will be available at an address that uses this namespace as the reference for access. Example: https://oppsec.blob.core.windows.net.\nContainer: A container is where all the blobs get stored; they work similarly to a directory in a file system. A good thing is there is no limit to how many blobs can be stored in a container, of course, because the purpose is to provide large storage access. A container name can be between 3 and 63 characters long and doesn\u0026rsquo;t support special characters besides the dash character (-).\nBlob: A blob is a binary large object and a storage option for any type of data that you want to store in a binary format. (I took this from Microsoft again)\nAzure Blob Storage diagram that I stole from Microsoft documentation\nAzure Blob Storage is basically Microsoft\u0026rsquo;s version of Amazon S3 Bucket or Google Cloud Drive. The main purpose is to serve access to a large scale of files and provide more flexibility in the storing process.\nWhy should I know about this? # Well, we\u0026rsquo;re hackers, or pentesters\u0026hellip; so we should know about a bunch of things. Today, it is extremely easy to find websites that use Microsoft services/technologies like IIS, ASP.NET, and now, Azure services, like Azure Blob Storage. If we understand the environment that we are fighting in, we know how to find vulnerabilities and create a good report for the client. I have already done a lot of pentests on clients that use Azure Blob Storage and discovered interesting info and sensitive data about the web app, infrastructure, or environment I was attacking with this knowledge.\nNow that you understand the importance of knowing what Azure Blob Storage is, we can start talking about the good part: the vulnerabilities that we can find while dealing with this service.\nAnonymous Access # The main advantage of Azure Blobs compared to other Azure artifacts like Azure Files (SMB and REST), Azure Queues, and Azure Tables is that Azure Blobs allow anonymous public read access, as we can see in the image below: With anonymous access and the right request, we can enumerate all the blobs (files) inside the target Azure Blob Storage and find really good information. As we said before, the base URL for an Azure Blob Storage is STORAGE_ACCOUNT_NAME.blob.core.windows.net, so you need to first discover the Storage Account name. It can be easily discovered if the web app makes a direct request for the file it needs. For example: In the image above, before the first dot is the storage account name. If you can\u0026rsquo;t find the storage account this way, I recommend trying three things:\nGoogle Dorking Use the company\u0026rsquo;s name Bruteforce with a custom wordlist Try using FFUF with a custom wordlist that combines the company name and a generic storage name, like amazoncontent, amazonstorage, amazonfiles.\nIf you can find a valid Azure Blob Storage domain, you\u0026rsquo;re probably going to find a page similar to this: As we can see in the image above, the service is asking for the parameter \u0026ldquo;comp\u0026rdquo;. If we look at Microsoft\u0026rsquo;s documentation, it says we can enumerate container names using ?comp=list, but this never worked for me. In an ideal world, like the first image I showed you, the container name will be in the URL. Example: https://oppsec.blob.core.windows.net/static/js/jquery.js — static is the container name. Again, you can use FFUF to enumerate container names. As you can see, the container name is static, a common word.\nThe main problem here is Azure Blob Storage does not indicate if the container name is valid or not, i.e. static can be a valid container name and notnotnotvalid invalid but we will get the same response for both:\n\u0026lt;Error\u0026gt; \u0026lt;Code\u0026gt;ResourceNotFound\u0026lt;/Code\u0026gt; \u0026lt;Message\u0026gt; The specified resource does not exist. RequestId:4f8c64bf-701e-0024-4099-3cb3d7000000 Time:2024-11-22T04:47:01.2790826Z \u0026lt;/Message\u0026gt; \u0026lt;/Error\u0026gt; Accessing blobs from a container # But Microsoft is not an evil company, and there is a way to identify if the container name is valid or not. We need to append ?restype=container\u0026amp;comp=list or just ?comp=list to the end of the URL, and blobs will be listed. With this in mind, we can go back to FFUF and enumerate valid container names through this command:\nffuf -c -w /opt/SecLists/Discovery/Web-Content/common.txt --fc 404 --mc all -u https://oppsec.blob.core.windows.net/FUZZ?comp=list ffuf -c -w /opt/SecLists/Discovery/Web-Content/common.txt --fc 404 --mc all -u https://oppsec.blob.core.windows.net/FUZZ?restype=container\u0026amp;comp=list Of course, you can use the tool of your choice, but I really like FFUF and have been using it for the last few years.\nNow you can list the blobs. You just need to access the URL indicated by the Name or Url values. For example, if I want to access the .less file from the image I used above, the URL would be something like this: https://oppsec.blob.core.windows.net/static/backend/REDACTED/css/REDACTED.less I used this file as an example, but you can find internal documents by searching for files that end with pdf, csv, xlsx, xls, docx, or low-hanging fruits with js, zip, sql files. Or just adapt the search based on the environment you\u0026rsquo;re exploring. If the web app is developed with PHP, you can search for php, inc, bkp.\nAnother problem is Azure Blob Storage is used to store a large scale of files. If you want to find files that end with pdf, you will need to use CTRL+F on your browser and filter one by one. If that wasn\u0026rsquo;t enough, you may come across errors like FeatureVersionMismatch and will need to specify the x-ms-version header with the vlaue 2020-04-08.\nI\u0026rsquo;m a person that likes to develop tools/scripts and bring more convenience to my life. So, I developed a tool to help with Azure Blob Storage. I called it Blobber, and it is developed with Python and ChatGPT\u0026rsquo;s help.\nBlobber # Blobber automates the process of adding ?restype=container\u0026amp;comp=list to the URL, checks for errors, tries to bypass them, and lets you view only the really important data and filter by extensions with more convenience. You can skip the filter by extensions flag too, but be careful because a lot of content will be printed (probably).\nI will not release Blobber for now because I want to do more tests and not release a tool that does not work as expected. However, it will eventually be available on my GitHub. The repo will be accessible through this URL https://github.com/oppsec/blobber.\nConclusion # Today we learned a bit more about the Azure Blob Storage service and how valuable it is to find one with anonymous access enabled. I really enjoyed reading about this through Microsoft\u0026rsquo;s documentation and developing this script (Blobber). In my opinion, this is the best way to learn something new and improve your skills. I hope all you guys liked this post and learned something new. I hope to see you again soon.\nReferences # https://learn.microsoft.com/en-us/azure/storage/blobs/ https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blobs-overview https://learn.microsoft.com/en-us/rest/api/storageservices/blob-service-rest-api https://learn.microsoft.com/en-us/rest/api/storageservices/blob-service-concepts https://learn.microsoft.com/en-us/rest/api/storageservices/enumerating-blob-resources https://learn.microsoft.com/en-us/rest/api/storageservices/operations-on-containers ","date":"22 November 2024","externalUrl":null,"permalink":"/posts/attacking-azure-blob-storage-services/","section":"Posts","summary":"","title":"Attacking Azure Blob Storage Services","type":"posts"},{"content":"","date":"22 November 2024","externalUrl":null,"permalink":"/tags/azure/","section":"Tags","summary":"","title":"Azure","type":"tags"},{"content":"","date":"22 November 2024","externalUrl":null,"permalink":"/tags/microsoft/","section":"Tags","summary":"","title":"Microsoft","type":"tags"},{"content":"","date":"22 November 2024","externalUrl":null,"permalink":"/tags/pentest/","section":"Tags","summary":"","title":"Pentest","type":"tags"},{"content":"","date":"22 November 2024","externalUrl":null,"permalink":"/tags/windows/","section":"Tags","summary":"","title":"Windows","type":"tags"},{"content":"","date":"24 October 2024","externalUrl":null,"permalink":"/tags/active-directory/","section":"Tags","summary":"","title":"Active Directory","type":"tags"},{"content":"","date":"24 October 2024","externalUrl":null,"permalink":"/tags/ldap/","section":"Tags","summary":"","title":"Ldap","type":"tags"},{"content":" O que é? # O Security Descriptor ou ntSecurityDescriptor, é um atributo de segurança do Windows que contém uma estrutura de dados representativa das permissões e propriedades daquele objeto em questão. Podemos interpretar o mesmo como uma ideia do escopo de permissões do X sobre Y. O ntSecurityDescriptor está presente desde as versões superiores do Windows Server 2000 e se manteve o mesmo desde então.\nO Security Descriptor é um representação compactada binária da segurança associada a objeto pertecente ao ambiente. Para comprovação disso, podemos tentar extrair o Security Descriptor de um usuário ou grupo por meio de uma query LDAP e vermos seu formato puro.\nÉ importante salientar que o ntSecurityDescriptor é utilizado por DACLs, SACLs, e ACL. Esses três atributos são responsáveis por representar as permissões desse objeto consumindo os dados do ntSecurityDescriptor. Essas permissões são de quem representa aquele objeto, quem pode acessar esse objeto e o que pode fazer com o mesmo, informações de auditoria do objeto e restrições sobre tal.\nACL: Access Control List é uma lista de proteções de seguranças que são aplicadas sobre um objeto. Deve-se entender que objetos podem ser um arquivo, processo, evento, ou tudo aquilo que também tiver um “Security Descriptor”; ACE: Access Control Entries são entrada de dados de ACLs (Access Control List). Uma ACE contém uma lista de permissões sobre um SID que irá identificar se tais permissões participam dos escopos: Allowed, Denied ou Audited; DACL: Discretionary Access Control List é o responsável por identificar os administradores ou objetos que tem permissões ou não sobre objetos protegidos. Caso um processo tente interagir com um objeto protegido, o sistema irá requisitar ao que ACE busque na DACL se aquele autor em questão tem as permissões necessárias; SACL: System Access Control List é uma lista que permite que adminstradores registrem tentativas de interação ou acesso a um objeto protegido. Cada ACE irá especificar as tentativas de acesso sobre aquele item e fará com que o sistema armazene essa tentativa no Security Event Log; De acordo com a Microsoft, o ntSecurityDescriptor utiliza de um sistema chamado Security Descriptor String Format. O Security Descriptor String Format é um formato ou sistema de texto responsável por armazenar ou transportar a informação do ntSecurityDescriptor. Isso é feito por duas funções chamadas ConvertSecurityDescriptorToStringSecurityDescriptorA e ConvertStringSecurityDescriptorToSecurityDescriptorA. Essas duas funções são utilizadas para o trabalho de conversão dos Security Descriptor.\nÉ possível transformar um “String Security Descriptor“ para um Security Descriptor Absoluto através de outra função que é chamada de MakeAbsoluteSD. Essas três funções iram retornar valores não nulos, caso todos os argumentos necessários forem repassados e serem válidos. Com o seu retorno, é possível extrair o formato do Security Descriptor.\nPara que as funções citadas acima possam descrever o formato do Security Descriptor, é utilizado a tecnologia SDDL (Security Descriptor Definition Language) que irá fazer essa tradução e permitir que as funções possam representar elas em texto. Aqui estão alguns exemplos de SDDL retirados do artigo da Microsoft:\nExemplos # Regra: Qualquer usuário poderá executar esse objeto se ele seguir as seguintes condições:\nO título dele ser PM A divisão ou setor dele for Financeiro ou Vendas d:(XA; ;FX;;;S-1-1-0; (@User.Title==\u0026#34;PM\u0026#34; \u0026amp;\u0026amp; (@User.Division==\u0026#34;Financeiro\u0026#34; || @User.Division ==\u0026#34;Vendas\u0026#34;))) Regra 2: Permite leitura do objeto se o usuário seguir as seguintes condições:\nSeu login ter sido feito a partir de um Smart Card É pertencente do grupo Backup Operator Está conectado em uma máquina com o BitLocker ativo D:(XA; ;FR;;;S-1-1-0; (Member_of {SID(Smartcard_SID), SID(BO)} \u0026amp;\u0026amp;@Device.Bitlocker)) Qual a sua importância? # Através do Security Descriptor, pode-se compreender qual o escopo de privilégios que aquele ativo terá sobre um item de seu interesse ou que haverá uma possível interação. Com isso em mente, a Microsoft desenvolveu esse atributo expressivo para que fosse alocado sobre os objetos do ambiente Active Directory e pudesse trabalhar as questões de controle de acesso. Atualmente, ele é utilizado por outras classes do ambiente Active Directory como:\nsamDomainBase: A classe base para a definição de domínios; securityPrincipal: Armazena informações de segura sobre um objeto; top: A classe de mais alto nível que é de onde todas as classes derivam; Hoje em dia, ferramentas como o BloodHound usufruem de ACEs e DACLs para identificar as permissões que um objeto tem sobre o outro, e assim, poder construir caminhos de exploração por meio de fragilidades do objeto X sobre o objeto Y.\nTrabalhando com o ntSecurityDescriptor # O ntSecurityDescriptor segue o seguinte formato O:BAG:BAD:S:, onde:\nO: Owner BAG e BAD serão utilizados para representar quem tem permissão de interação e quem não tem sobre aquele objeto. G é Granted e D é Deny. S representará o SACL. O atributo Owner irá indicar o proprietário por meio do SID do objeto, o BAG e o BAD são especificadores de controle de acesso e o SACL para poder armazenar as tentativas de interação com o objeto alvo. De uma maneira simples, se expandíssemos um Security Descriptor, esse seria o formato dele:\nComo podemos ver, o Owner e PrimaryGroup são as representações do proprietário daquele Security Descriptor. Com isso, podemos partir para a leitura da DACL que trará informações sobre a ACE do objeto protegido. Em um contexto de segurança ofensiva, o que diretamente nos importa seria o Access Mask dessa ACE.\nCom isso em mente, podemos capturar o Security Descriptor de objetos (usuários, grupos, etc) e lermos suas permissões e identificar possíveis fragilidades que atacantes podem utilizar para escalonar privilégios dentro de um ambiente Active Directory. Para isso, incrementei um módulo na minha ferramenta breads que irá buscar pelo valor do ntSecurityDescriptor de todos os objetos do ambiente através da query objectClass=(*) e checar as permissões se baseando no valor de ACE_MASK. Esses valores são hexadecimais que quando calculados, podem ser lidos como bits representantes de permissão. Essa é a tabela de permissões:\nEsse é o pedaço do código da minha ferramenta que irá realizar essa busca. O object_ntsd representa o acesso ao atributo ntSecurityDescriptor daquele objeto; já a variável sd está utilizando de uma classe do projeto Impacket para realizar a leitura dos bytes do Security Descriptor. Por fim, percorremos pelas chaves retornada da variável sd e acessamos seus valores respectivamente.\n# ... object_ntsd = attribute[\u0026#34;attributes\u0026#34;][\u0026#34;nTSecurityDescriptor\u0026#34;] sd = SR_SECURITY_DESCRIPTOR(data=object_ntsd) if sd[\u0026#34;Dacl\u0026#34;]: for ace in sd[\u0026#34;Dacl\u0026#34;].aces: ace_object = ace[\u0026#34;Ace\u0026#34;] # Ace_Object Vars: Mask, Sid ace_mask = ace_object[\u0026#34;Mask\u0026#34;][\u0026#34;Mask\u0026#34;] Após um tratamento sobre os hexadecimais retornados e quais são suas representações com base na documentação da Microsoft, podemos esperar um resultado como esse abaixo. Ressalto que foi utilizado uma conta participante do grupo de Domain Admins.\nConclusão # Assim, podemos compreender a relevância do ntSecurityDescriptor no Active Directory e como podemos utilizar dele para encontrar meios para realizar uma escalação de privilégios por meio de objetos presentes no ambiente. Como citado anteriormente, a ferramenta BloodHound faz um ótimo trabalhando usufruindo desse atributo para construir caminhos e gráficos com base nas informações coletadas do ambiente. Entende-se que tudo isso é principalmente útil para atacantes, todavia, esse tipo de processo também é de grande utilidade também para os times de operações defensivas, visto que poderão encontrar fragilidades na arquitetura monitorada.\nReferências # https://learn.microsoft.com/en-us/windows/win32/adschema/a-ntsecuritydescriptor https://learn.microsoft.com/en-us/windows/win32/adschema/c-samdomainbase https://learn.microsoft.com/en-us/windows/win32/adschema/c-top https://learn.microsoft.com/en-us/windows/win32/secauthz/security-descriptor-string-format?redirectedfrom=MSDN https://learn.microsoft.com/en-us/windows/win32/secgloss/a-gly https://learn.microsoft.com/en-us/windows/win32/secgloss/d-gly https://learn.microsoft.com/en-us/windows/win32/secauthz/access-control-lists https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-dtyp/4f4251cc-23b6-44b6-93ba-69688422cb06 https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-dtyp/7d4dac05-9cef-4563-a058-f108abecce1d https://github.com/fortra/impacket/blob/f8899e65f16c50b871863528d419cfb701a5a3e3/impacket/ldap/ldaptypes.py https://learn.microsoft.com/en-us/windows/win32/api/iads/ne-iads-ads_rights_enum https://www.installsetupconfig.com/win32programming/accesscontrollistacl2_1.html ","date":"24 October 2024","externalUrl":null,"permalink":"/posts/security-descriptor/","section":"Posts","summary":"","title":"Security Descriptor, o que é e onde vive.","type":"posts"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]